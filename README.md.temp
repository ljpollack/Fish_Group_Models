# Bayesian Models For Fish Group Studies

These are some first stabs at Bayesian GLMMs for fish group personality data lovingly collected by [Lea Pollack](github.com/ljpollack), using the `brms` package, the UC Davis FARM cluster, and stuff learned from Richard McElreath's class.

# Repo Organization

## Organization To-Do

1) ~~pull all models down from FARM~~
2) compartmentalize by specific model to be fitted
3) make sure FARM and local relative paths for model scripts match so we can run the FARM `.R` scripts locally to test 

### FARM Transfer

1) start with a single model
2) take file from FARM pulled folder, clean it up (put in new STDOUT, make sure directories look good, take out data cleaning elements and transfer them to data cleaning scripts)
3) when file is cleaned, put it into a new folder that will have the correct cleaned structure
4) when all the files are cleaned and put into new structure, you can take that whole new structure and replace the local repo's "files for farm" folder
5) from here, transfer the proper files from the local repo "files for farm** into the non-farm folders, so the models match between "files for farm** and everywhere else

**actually, should consider just making the files match exactly. one version on the local repo, push this to the FARM, anything that gets pulled back with changes gets pulled directly on top of the local file. keeps everything the same between both places**

# Fitted Models

Listed by response variable.

## Latency

### Known Food

#### *BEST MODEL:* Multi-level hurdle negative binomial model
```
family = hurdle_negbinomial,
            latency ~ 1 + treatment + trial +
              (1 + treatment + trial | group_ID) +
              (1 + treatment + trial | tank)
```
Model Info:

- File Location:
- Data Used:
- Post-Model Script:

### Novel Food

#### *BEST MODEL:* Multi-level hurdle negative binomial model
```
family = hurdle_negbinomial,
               latency ~ 1 + treatment + novel_food +
                 (1 + treatment + novel_food | group_ID) +
                 (1 + treatment + novel_food | tank)
```
Model Info:

- File Location:
- Data Used:
- Post-Model Script:

## Chases

### Number of Chases 

#### *BEST MODEL:* 
```
```
Model Info:

- File Location:
- Data Used:
- Post-Model Script:

## Food Eaten

# To-Do Models

1) Latency post-predator cue
    - same structure as the latency for known food model
2) In latency models, add explicit predictors for the hurdle portion
3) Look for correlation between aggression (chase count) and % food eaten
    - predictor would be aggression
    - so we'll add aggression into a % of food eaten model
    - there are 3x more aggression data points than food eaten data points, since there were 3 aggression trials but only 1 trial where food eaten was measured
        - do we use **all** the aggression data points or just the ones that correspond to the trial where food eaten was recorded? *need to think about this*
            - could maybe use 3 separate aggression predictors: one for each assay in which aggression was measured. so a "activity assay aggression" predictor, a "known food aggression" predictor (which is the one where % food was actually measured), and a "novel food aggression" predictor
4) for "number of chases" model, should run it once with a per-capita measure of # of chases
    - problem here is can't use nbinom model because we don't have integers any more
    - should plot these data and look at the per-capita rate
    - look into using something like `numchases | trials(group_size)`, like in the aggregated binomial model of % food eaten, this would be instead of a per-capita numchase value

# Other To-Do

1) Figure out way to push large model `.rds` files to GitHub or look into other storage method
2) Finish plot-generating functions
3) Clean up pre-analysis data cleaning scripts
4) Make a **separate** post-analysis script for *each* model
5) Shade the parameter density plots with a 95% posterior density interval
